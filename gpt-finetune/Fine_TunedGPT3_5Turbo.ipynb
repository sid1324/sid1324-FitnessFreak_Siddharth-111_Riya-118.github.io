{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVoU7VrzGzxn",
        "outputId": "358400b4-c79f-4e76-9a8e-6d9e009b02e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: C:\\Users\\91982\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: C:\\Users\\91982\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tiktoken in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.5.1)"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: C:\\Users\\91982\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken) (2023.10.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Requirement already satisfied: Gradio in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.44.4)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (5.1.1)\n",
            "Requirement already satisfied: fastapi in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.103.1)\n",
            "Requirement already satisfied: ffmpy in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.3.1)\n",
            "Requirement already satisfied: gradio-client==0.5.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.5.1)\n",
            "Requirement already satisfied: httpx in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.25.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.17.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (6.1.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (3.8.0)\n",
            "Requirement already satisfied: numpy~=1.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (1.26.0)\n",
            "Requirement already satisfied: orjson~=3.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (3.9.7)\n",
            "Requirement already satisfied: packaging in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (23.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (2.1.1)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (10.0.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (2.3.0)\n",
            "Requirement already satisfied: pydub in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (4.8.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (0.23.2)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from Gradio) (11.0.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from gradio-client==0.5.1->Gradio) (2023.9.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from altair<6.0,>=4.2.0->Gradio) (4.19.1)\n",
            "Requirement already satisfied: toolz in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from altair<6.0,>=4.2.0->Gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.14.0->Gradio) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub>=0.14.0->Gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib~=3.0->Gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<3.0,>=1.0->Gradio) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<3.0,>=1.0->Gradio) (2023.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->Gradio) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.3 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->Gradio) (2.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests~=2.0->Gradio) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests~=2.0->Gradio) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests~=2.0->Gradio) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests~=2.0->Gradio) (2023.7.22)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn>=0.14.0->Gradio) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn>=0.14.0->Gradio) (0.14.0)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastapi->Gradio) (3.7.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastapi->Gradio) (0.27.0)\n",
            "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx->Gradio) (0.18.0)\n",
            "Requirement already satisfied: sniffio in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx->Gradio) (1.3.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click>=7.0->uvicorn>=0.14.0->Gradio) (0.4.6)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->Gradio) (0.10.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\91982\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->Gradio) (1.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: C:\\Users\\91982\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install numpy\n",
        "!pip install tiktoken\n",
        "!pip install Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "WysuPFYQHfCq",
        "outputId": "70b49068-9905-4fdb-b7ea-d9c2dd76c098"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91982\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import tiktoken\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_ofhSD5BII1W"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO8Q9d0b4UGH",
        "outputId": "53ba5d2f-7013-44b7-9435-b747a2870d37"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\riyar\\OneDrive\\Desktop\\gpt-finetune\\Fine_TunedGPT3_5Turbo.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/riyar/OneDrive/Desktop/gpt-finetune/Fine_TunedGPT3_5Turbo.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/riyar/OneDrive/Desktop/gpt-finetune/Fine_TunedGPT3_5Turbo.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySonCJu2I1KD",
        "outputId": "e59780cb-77d2-4e57-abb5-f3b8a8ff0461"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JSON decode error for cell '{\"messages\":[{\"role\":\"system\",\"content\":\"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"},{\"role\":\"assitant\",\"content\":\"I am healthy, I want to improve my fitness. Recommend me a few exercises with reps and sets.\"},{\"role\":\"assitant\",\"\"content\":\"{\"I'm happy to assist you on that! Following would be some recommended exercises to improve your physical fitness-\n",
            "Body part-Chest,Type of muscle- Upper Chest,Workout- Incline dumbbell press,Sets- 3-4,Reps per set- 8-12.\n",
            "Body part-Back,Type of muscle- Lower,Workout- Bent over Rows,Sets- 3-4,Reps per set- 8-12.\n",
            "Body part-Legs,Type of muscle- Calf,Workout- Standing Calf raises ,Sets- 3-4,Reps per set- 15-20.\n",
            "Body part-Abs,Type of muscle- Middle,Workout- Bicycle crunches,Sets- 3-4,Reps per set- 12-15.\"}]}': Expecting ':' delimiter: line 1 column 366 (char 365)\n",
            "JSON decode error for cell '{\"messages\":[{\"role\":\"system\",\"content\":\"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"},{\"role\":\"assitant\",\"content\":\"I am obese, I want to lose weight. Recommend me a few exercises.\"},{\"role\":\"assitant\",\"\"content\":\"{\"I'm happy to assist you on that! Following would be some recommended exercises to help you cut down on some weight-\n",
            "Body part-Legs,Type of muscle- Glutes,Workout- Barbell hip thrusts,Sets- 3-4,Reps per set- 8-12.\n",
            "Body part-Arms,Type of muscle- Tricep,Workout- Close-grip bench press,Sets- 3-4,Reps per set- 8-12.\n",
            "Body part-Legs,Type of muscle- Hamstrings,Workout- Romanian Deadlift ,Sets- 3-4,Reps per set- 10-15.\n",
            "Body part-Abs,Type of muscle- Upper,Workout- Crunches,Sets- 3-4,Reps per set- 12-15.\"}]}': Expecting ':' delimiter: line 1 column 338 (char 337)\n",
            "JSON decode error for cell '{\"messages\":[{\"role\":\"system\",\"content\":\"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"},{\"role\":\"assitant\",\"content\":\"I am underweight and I want to gain muscle. Recommend me a few exercises.\"},{\"role\":\"assitant\",\"\"content\":\"{\"I'm happy to assist you on that! Following would be some recommended exercises to improve your physical fitness-\n",
            "Body part-Chest,Type of muscle- Upper Chest,Workout- Bench press,Sets- 4-5,Reps per set- 8-10.\n",
            "Body part-Back,Type of muscle- Upper,Workout- Lat Pull downs,Sets- 3-4,Reps per set- 12-15.\n",
            "Body part-Legs,Type of muscle- Quadriciples,Workout- Leg press ,Sets- 3-4,Reps per set- 15-20.\n",
            "Body part-Back,Type of muscle- Upper,Workout- Pull overs,Sets- 2-3,Reps per set- 15-18\"}]}': Expecting ':' delimiter: line 1 column 347 (char 346)\n"
          ]
        }
      ],
      "source": [
        "#Load CSV data in\n",
        "csv_file_path = r'C:\\Users\\91982\\Downloads\\gpt-finetune\\gpt-finetune\\fitness.csv'\n",
        "cleaned_data = []\n",
        "\n",
        "with open(csv_file_path, 'r', encoding='utf-8-sig') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    for row in csv_reader:\n",
        "        for cell in row:\n",
        "            try:\n",
        "                # Replace square brackets and inner double quotes that are problematic\n",
        "                cell = cell.replace('[\"', '').replace('\"]', '').replace('\\\\\"', '\"')\n",
        "\n",
        "                # Load each cell as a JSON object\n",
        "                cell_json = json.loads(cell)\n",
        "\n",
        "                # Now that the content is clean, append to cleaned_data list\n",
        "                cleaned_data.append(cell_json)\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"JSON decode error for cell '{cell}': {e}\")\n",
        "\n",
        "jsonl_file_path = r'C:\\Users\\91982\\Downloads\\gpt-finetune\\gpt-finetune\\fitness-json.jsonl'\n",
        "# Write cleaned data to a JSONL file\n",
        "with open(jsonl_file_path, 'w', encoding='utf-8') as jsonl_file:\n",
        "    for item in cleaned_data:\n",
        "        jsonl_file.write(json.dumps(item) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NNdePOiKuKW",
        "outputId": "a550d8dc-2246-44ec-c9d5-54c739eacbfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples: 30\n",
            "First example:\n",
            "{'role': 'system', 'content': \"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}\n",
            "{'role': 'user', 'content': 'I want to get in shape for summer. What exercises do you recommend?'}\n",
            "{'role': 'assistant', 'content': \"I'd be delighted to assist you with that! Here are some recommended exercises to help you get in shape for summer: Body part-Chest, Type of muscle-Upper Chest, Workout-Incline dumbbell press, Sets-3-4, Reps per set-8-12. Body part-Back, Type of muscle-Lower, Workout-Bent over Rows, Sets-3-4, Reps per set-8-12. Body part-Legs, Type of muscle-Calf, Workout-Standing Calf raises, Sets-3-4, Reps per set-15-20. Body part-Abs, Type of muscle-Middle, Workout-Bicycle crunches, Sets-3-4, Reps per set-12-15.\"}\n",
            "No errors found\n",
            "Num examples missing system message: 1\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 2, 3\n",
            "mean / median: 2.966666666666667, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 93, 217\n",
            "mean / median: 189.06666666666666, 195.5\n",
            "p5 / p95: 167.4, 207.2\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 32, 156\n",
            "mean / median: 129.0, 133.5\n",
            "p5 / p95: 105.4, 143.60000000000002\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n",
            "Dataset has ~5672 tokens that will be charged for during training\n",
            "By default, you'll train for 4 epochs on this dataset\n",
            "By default, you'll be charged for ~22688 tokens\n",
            "Estimated cost for fine-tuning: approximately $0.18\n"
          ]
        }
      ],
      "source": [
        "#from OpenAI website to format data;  https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset\n",
        "\n",
        "# Next, we specify the data path and open the JSONL file\n",
        "\n",
        "data_path = r'C:\\Users\\91982\\Downloads\\gpt-finetune\\gpt-finetune\\fitness-json.jsonl'\n",
        "\n",
        "# Load dataset\n",
        "with open(data_path) as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# We can inspect the data quickly by checking the number of examples and the first item\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "# Now that we have a sense of the data, we need to go through all the different examples and check to make sure the formatting is correct and matches the Chat completions message structure\n",
        "\n",
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for ex in dataset:\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message in messages:\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        if not content or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n",
        "\n",
        "# Beyond the structure of the message, we also need to ensure that the length does not exceed the 4096 token limit.\n",
        "\n",
        "# Token counting functions\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "# not exact!\n",
        "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")\n",
        "\n",
        "# Last, we can look at the results of the different formatting operations before proceeding with creating a fine-tuning job:\n",
        "\n",
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")\n",
        "\n",
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "TARGET_EPOCHS = 4\n",
        "MIN_EPOCHS = 1\n",
        "MAX_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")\n",
        "\n",
        "# Calculate the estimated cost for fine-tuning\n",
        "cost_per_100k_tokens = 0.80  # Cost for every 100,000 tokens\n",
        "estimated_cost = ((n_epochs * n_billing_tokens_in_dataset) / 100000) * cost_per_100k_tokens\n",
        "print(f\"Estimated cost for fine-tuning: approximately ${estimated_cost:.2f}\") #I added this for actual cost based on current pricing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GME1BGqXNGMQ"
      },
      "outputs": [],
      "source": [
        "# Function to save the dataset as a JSONL file\n",
        "def save_to_jsonl(conversations, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for conversation in conversations:\n",
        "            json_line = json.dumps(conversation)\n",
        "            file.write(json_line + '\\n')\n",
        "\n",
        "# Specify the path where you want to save the JSONL file in your Google Drive\n",
        "jsonl_file_path = r'C:\\Users\\91982\\Downloads\\gpt-finetune\\gpt-finetune\\fitness-json-clean.jsonl'\n",
        "# Save the dataset to the specified file path\n",
        "save_to_jsonl(dataset, jsonl_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d403QpVVN3BU",
        "outputId": "8410c3fd-f5e5-416d-845d-9b50527f0e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training file id: file-NxYKcePrv0xYXZkwUqB8iXPX\n"
          ]
        }
      ],
      "source": [
        "#Upload data for training\n",
        "training_file_name = r'C:\\Users\\91982\\Downloads\\gpt-finetune\\gpt-finetune\\fitness-json-clean.jsonl'\n",
        "\n",
        "training_response = openai.File.create(\n",
        "    file=open(training_file_name, \"rb\"), purpose=\"fine-tune\"\n",
        ")\n",
        "training_file_id = training_response[\"id\"]\n",
        "\n",
        "#Gives training file id\n",
        "print(\"Training file id:\", training_file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlZEZYGTOY-L",
        "outputId": "23dfb64d-2cd4-40c1-ea8c-7cffa88a07be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-yZlIe8Auo67xxDBDF07vSDCR\",\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"created_at\": 1698133611,\n",
            "  \"finished_at\": null,\n",
            "  \"fine_tuned_model\": null,\n",
            "  \"organization_id\": \"org-KucJSzdCEcid5VwezGnR7GXP\",\n",
            "  \"result_files\": [],\n",
            "  \"status\": \"validating_files\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-vx27bAJ1gx5TCCAD71TrXlz1\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": \"auto\"\n",
            "  },\n",
            "  \"trained_tokens\": null,\n",
            "  \"error\": null\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "#Create Fine-Tuning Job\n",
        "suffix_name = \"ted\"\n",
        "\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=training_file_id,\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    suffix=suffix_name,\n",
        ")\n",
        "\n",
        "job_id = response[\"id\"]\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xyzue2SPYaZ",
        "outputId": "86b8172c-5ae7-47ea-9337-afb86c462be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 43/90: training loss=0.26\n",
            "Step 44/90: training loss=0.84\n",
            "Step 45/90: training loss=0.60\n",
            "Step 46/90: training loss=0.43\n",
            "Step 47/90: training loss=0.27\n",
            "Step 48/90: training loss=0.22\n",
            "Step 49/90: training loss=0.17\n",
            "Step 50/90: training loss=0.60\n",
            "Step 51/90: training loss=0.69\n",
            "Step 52/90: training loss=0.52\n",
            "Step 53/90: training loss=0.11\n",
            "Step 54/90: training loss=0.17\n",
            "Step 55/90: training loss=0.51\n",
            "Step 56/90: training loss=0.56\n",
            "Step 57/90: training loss=0.31\n",
            "Step 58/90: training loss=0.74\n",
            "Step 59/90: training loss=0.09\n",
            "Step 60/90: training loss=0.33\n",
            "Step 61/90: training loss=0.09\n",
            "Step 62/90: training loss=0.31\n",
            "Step 63/90: training loss=0.47\n",
            "Step 64/90: training loss=0.36\n",
            "Step 65/90: training loss=0.22\n",
            "Step 66/90: training loss=0.14\n",
            "Step 67/90: training loss=0.52\n",
            "Step 68/90: training loss=0.11\n",
            "Step 69/90: training loss=0.44\n",
            "Step 70/90: training loss=0.25\n",
            "Step 71/90: training loss=0.20\n",
            "Step 72/90: training loss=0.12\n",
            "Step 73/90: training loss=0.25\n",
            "Step 74/90: training loss=0.13\n",
            "Step 75/90: training loss=0.41\n",
            "Step 76/90: training loss=0.04\n",
            "Step 77/90: training loss=0.05\n",
            "Step 78/90: training loss=0.24\n",
            "Step 79/90: training loss=0.06\n",
            "Step 80/90: training loss=0.07\n",
            "Step 81/90: training loss=0.50\n",
            "Step 82/90: training loss=0.35\n",
            "Step 83/90: training loss=0.83\n",
            "Step 84/90: training loss=0.09\n",
            "Step 85/90: training loss=0.62\n",
            "Step 86/90: training loss=0.11\n",
            "Step 87/90: training loss=0.06\n",
            "Step 88/90: training loss=0.36\n",
            "Step 89/90: training loss=0.21\n",
            "Step 90/90: training loss=0.23\n",
            "New fine-tuned model created: ft:gpt-3.5-turbo-0613:personal:ted:8D6e8BCy\n",
            "The job has successfully completed\n"
          ]
        }
      ],
      "source": [
        "#list events as fine-tuning progresses\n",
        "job_id=\"ftjob-yZlIe8Auo67xxDBDF07vSDCR\"\n",
        "response = openai.FineTuningJob.list_events(id=job_id, limit=50)\n",
        "\n",
        "events = response[\"data\"]\n",
        "events.reverse()\n",
        "\n",
        "for event in events:\n",
        "    print(event[\"message\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUgVjlQxUMhw",
        "outputId": "dc3499cb-50a1-4063-f721-867f94114ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"object\": \"fine_tuning.job\",\n",
            "  \"id\": \"ftjob-yZlIe8Auo67xxDBDF07vSDCR\",\n",
            "  \"model\": \"gpt-3.5-turbo-0613\",\n",
            "  \"created_at\": 1698133611,\n",
            "  \"finished_at\": 1698134502,\n",
            "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal:ted:8D6e8BCy\",\n",
            "  \"organization_id\": \"org-KucJSzdCEcid5VwezGnR7GXP\",\n",
            "  \"result_files\": [\n",
            "    \"file-0RcwuNouwCgDD5Wampsp5DWs\"\n",
            "  ],\n",
            "  \"status\": \"succeeded\",\n",
            "  \"validation_file\": null,\n",
            "  \"training_file\": \"file-vx27bAJ1gx5TCCAD71TrXlz1\",\n",
            "  \"hyperparameters\": {\n",
            "    \"n_epochs\": 3\n",
            "  },\n",
            "  \"trained_tokens\": 16836,\n",
            "  \"error\": null\n",
            "}\n",
            "\n",
            "Fine-tuned model id: ft:gpt-3.5-turbo-0613:personal:ted:8D6e8BCy\n"
          ]
        }
      ],
      "source": [
        "#retrieve fine-tune model id\n",
        "response = openai.FineTuningJob.retrieve(job_id)\n",
        "fine_tuned_model_id = \"ft:gpt-3.5-turbo-0613:personal:ted:8D6e8BCy\"\n",
        "\n",
        "print(response)\n",
        "print(\"\\nFine-tuned model id:\", fine_tuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L7IEZScVi62",
        "outputId": "78b738ea-b118-4979-ece9-6f045ce0a5ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'role': 'system', 'content': \"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"}, {'role': 'user', 'content': 'I am a 40 year old woman, how can i lose weight quickly?. Recommned exercises with sets and reps.'}]\n"
          ]
        }
      ],
      "source": [
        "#Test it out!\n",
        "test_messages = []\n",
        "\n",
        "system_message = \"You are an overly friendly exercise recommending fitness chatbot named Ted who just loves to help people, and you're not satisfied unless the customer is completely satisfied.\"\n",
        "test_messages.append({\"role\": \"system\", \"content\": system_message})\n",
        "user_message = \"I am a 40 year old woman, how can i lose weight quickly?. Recommned exercises with sets and reps.\"\n",
        "test_messages.append({\"role\": \"user\", \"content\": user_message})\n",
        "\n",
        "print(test_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ2FtN_IVyxC",
        "outputId": "ae4fa086-e016-49b4-d766-e2af9509b124"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, 40-year-old woman! Here's a workout routine to help you lose weight quickly. Remember to consult with a healthcare professional before starting any new fitness program. Legs, Type of muscle-Quadriceps, Workout-Leg press, Sets-3-4, Reps per set-8-12. Legs, Type of muscle-Quadriceps, Workout-Leg extensions, Sets-3-4, Reps per set-10-15. Legs, Type of muscle-Hamstrings, Workout-Romanian deadlifts, Sets-3-4, Reps per set-8-12. Legs, Type of muscle-Hamstrings, Workout-Leg curls, Sets-3-4, Reps per set-10-15.\n"
          ]
        }
      ],
      "source": [
        "#OpenAI Chat Completions\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=fine_tuned_model_id, #can test it against gpt-3.5-turbo to see difference\n",
        "    messages=test_messages,\n",
        "    temperature=0,\n",
        "    max_tokens= 500\n",
        ")\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "TjYFpQkDWsQQ",
        "outputId": "23f1a257-ac52-462e-ab4d-267fb368343e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91982\\AppData\\Local\\Temp\\ipykernel_48856\\417028382.py:16: GradioUnusedKwargWarning: You have unused kwarg parameters in Interface, please remove them: {'input_labels': 'Question', 'output_labels': 'Response'}\n",
            "  iface = gr.Interface(fn=generate_completion,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://464a14b5a54391e46c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://464a14b5a54391e46c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Gradio for a better UI\n",
        "def generate_completion(user_prompt):\n",
        "    hidden_context = \"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": hidden_context},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=fine_tuned_model_id,\n",
        "        messages=messages,\n",
        "        max_tokens=500,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].strip()\n",
        "\n",
        "iface = gr.Interface(fn=generate_completion,\n",
        "                     inputs = \"text\",\n",
        "                     outputs='text',\n",
        "                     title=\"Ted the FitnessFreak\",\n",
        "                     input_labels=\"Question\",\n",
        "                     output_labels=\"Response\")\n",
        "\n",
        "iface.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
